---
permalink: /
title: "About"
# excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---



<div align="center">

*"To live life is to take decisions, and to take decisions is to reason and plan."* 

</div>

I am a fifth year Ph.D. student under the supervision of [Dr. Subbarao Kambhampati](https://rakaposhi.eas.asu.edu/) in [Yochan Lab](https://yochan-lab.github.io/home/) at the School of Computing & AI, Arizona State University. 

My research centers on the design and implementation of intelligent AI systems that empower human decision-making through the synergistic application of Large Language Models (LLMs), Large Reasoning Models (LRMs), and Reinforcement Learning (RL). My work critically examines the strengths and weaknesses of Foundational Models from a Human-AI Interaction standpoint, specifically investigating how these models can be tailored to meet the needs of real-world users and facilitate seamless human-AI collaboration for improved and more reliable decision outcomes across various domains.

Earlier, I completed my undergraduate studies majoring in Computer Science from [Delhi Technological University](http://dtu.ac.in/), India. In the past, I have worked and collaborated with research groups at [IIIT, Delhi](http://faculty.iiitd.ac.in/~arunb/) focusing on the topics of Preference-based Reinforcement Learning and Adversarial Machine Learning. 

## News

- [May 2025] Our paper titled **"Do Think Tags Really Help LLMs Plan? A Critical Evaluation of ReAct-Style Prompting"** was accepted at TMLR - Transactions on Machine Learning Research. Check out the [paper](https://openreview.net/forum?id=aFAMPSmNHR&referrer=%5BAuthor%20Console%5D(%2Fgroup%3Fid%3DTMLR%2FAuthors%23your-submissions)) and the [video](https://youtu.be/F8XNJ7tAcBE).
- [April 2025] I successfully defended my PhD Proposal Defense titled **"Role of Large Language Models in Human-AI Interaction: A Critical Appraisal"**.
- [March 2025] My YouTube podcast/interview titled [Beyond ChatGPT: The Future of Human-Aware AI Agents | Siddhant Bhambri- ASU AI Researcher](https://www.youtube.com/watch?si=G-84-w4ocMTyhlKy&v=tVg8JIOD_BY&feature=youtu.be) hosted by [Ones Changing The World - 1CW](https://www.youtube.com/@1CWpodcast) is out.
- [Janary 2025] My YouTube podcast titled [CS PhD in the USA Demystified: Your Ultimate Guide to Deciding, Preparing, Applying, and Succeeding!](https://www.youtube.com/watch?v=535CIprP_bw) hosted by [Turning Turing](https://www.youtube.com/@turningturing9217) is out.
- [August 2024] I completed my internship at Microsoft Research, Redmond. I worked with the [Augmented Learning and Reasoning](https://www.microsoft.com/en-us/research/group/augmented-learning-and-reasoning/) group on the topic of decision-making problems in Human-AI conversations.
- [May 2024] Our lab's position paper [LLMs Can't Plan, But Can Help Planning in LLM-Modulo Frameworks](https://icml.cc/virtual/2024/poster/33965) is accepted at [ICML 2024](https://icml.cc).
- [March 2024] I will be joining the [Augmented Learning and Reasoning](https://www.microsoft.com/en-us/research/group/augmented-learning-and-reasoning/) group at Microsoft Research, Redmond as a Research Intern for Summer 2024.
- [February 2024] I was awarded the ASU [School of Computing & AI](https://scai.engineering.asu.edu) Doctoral Fellowship for Spring 2024!
- [January 2024] Our work on investigating the [Theory of Mind abilities in Large Language Models](https://urldefense.com/v3/__https://maestro.acm.org/trk/clickp?ref=z16l2snue3_2-310b8_0x33ae25x01870&doi=3610978.3640767__;!!IKRxdwAv5BmarQ!ek06rhgjvhiBd0PdpQhFAr-PtFSKzG3LF_S9E8-UrHlgRi53ZzDEPNykdX3lrkchDF1BLYOH6A74ep_oNg$) was accepted at [HRI 2024](https://dl.acm.org/doi/proceedings/10.1145/3610978).

<style>
.news-section {
  background-color: #f5f5f5;
  padding: 20px;
  border-radius: 5px;
}

.news-section ul {
  list-style-type: none;
  padding: 0;
}

.news-section li {
  margin-bottom: 10px;
  padding: 5px;
  background-color: #ffffff;
  border-radius: 3px;
  box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
}
</style>