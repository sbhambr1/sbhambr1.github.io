---
title: "Preference Proxies: Evaluating Large Language Models in capturing Human Preferences in Human-AI Tasks"
collection: publications
permalink: /publication/2023-05-30-Preference-Proxies-Evaluating-Large-Language-Models-in-capturing-Human-Preferences-in-Human-AI-Tasks
# excerpt: 'In this work, we investigate the potential of Large Language Models (LLMs) to serve as effective human proxies by capturing human preferences in the context of collaboration with AI agents. Focusing on two key aspects of human preferences- explicability and sub-task specification in team settings - we explore LLMs’ ability to not only model mental states but also understand human reasoning processes. By developing scenarios where optimal AI performance relies on modeling human mental states and reasoning, our investigation involving two different preference types and a user study (with 17 participants) contributes valuable insights into the suitability of LLMs as “Preference Proxies” in various human-AI applications, paving the way for future research on the integration of AI agents with human users in Human-Aware AI tasks'
date: 2023-05-30
venue: 'ICML 2023 - Workshop on Theory of Mind in Communicating Agents, and Many Facets of Preference Learning Workshop'
paperurl: 'https://sbhambr1.github.io/files/Preference%20Proxies:%20Evaluating%20Large%20Language%20Models%20in%20capturing%20Human%20Preferences%20in%20Human-AI%20Tasks.pdf'
citation: 'Verma, Mudit, Siddhant Bhambri, and Subbarao Kambhampati. "Preference Proxies: Evaluating Large Language Models in capturing Human Preferences in Human-AI Tasks." In ICML 2023 Workshop The Many Facets of Preference-Based Learning. 2023.'
---